{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- `Written By   :` Mazi Boustani\n",
    "- `Date         :` 08/05/2021\n",
    "- `Purpose      :` Intoduction to Deep Learning and step by step code for traning a binary classification neural network from scratch to predict MNIST 0 and 1 digits\n",
    "\n",
    "All images captured from: https://youtu.be/5tvmMX8r_OM"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![NN](https://miro.medium.com/max/1100/0*61ZaNNpbpMtZLLpZ. \"MNIST Neural Network\")\n",
    "<center>[image source](https://www.youtube.com/watch?v=Ilg3gGewQ5U&t=522s&ab_channel=3Blue1Brown)</center>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## What is deep learning?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![what_is_deep_learning](images/what_is_deep_learning.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Two Supervised Learning algorithms"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Regression\n",
    "Regression predictive modeling is the task of approximating a mapping function (f) from input variables (X) to a continuous output variable (y).\n",
    "\n",
    "A continuous output variable is a real-value, such as an integer or floating point value. These are often quantities, such as amounts and sizes.\n",
    "\n",
    "### Classification\n",
    "Classification predictive modeling is the task of approximating a mapping function (f) from input variables (X) to discrete output variables (y).\n",
    "\n",
    "The output variables are often called labels or categories. The mapping function predicts the class or category for a given observation."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## The Perceptron\n",
    "\n",
    "The Perceptron (single neural) is fundamental building block of deep learning.\n",
    "\n",
    "Set of input multiply with corresponding weights and summed all together. Then pass it to an activation function."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![the_perceptron](images/the_perceptron.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "All activation functions\n",
    "![activation_functions](images/activation_functions.png)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Why using non linear activation function? Because we mostly see no linear data these days.\n",
    "![importance_activation_function](images/importance_activation_function.png)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![single_layer_NN](images/single_layer_NN.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![example_problem_NN](images/example_problem_NN.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![quantify_loss](images/quantify_loss.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![cost_function](images/cost_function.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![binary_cross_entropy_loss](images/binary_cross_entropy_loss.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![MSE_loss](images/MSE_loss.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![Loss_Optimization](images/Loss_Optimization.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![Gradient_descent](images/Gradient_descent.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![backprop](images/backprop.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![back_prop_w2](images/back_prop_w2.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![back_prop_w1](images/back_prop_w1.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![real_loss_plot](images/real_loss_plot.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![learning_rate](images/learning_rate.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![small_lr](images/small_lr.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![large_lr](images/large_lr.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![stable_lr](images/stable_lr.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![all_code](images/all_code.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![stochastic_gradient_descent](images/stochastic_gradient_descent.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![overfitting](images/overfitting.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![dropout](images/dropout.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![early_stop](images/early_stop.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Code Neural Network from Scratch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Download dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Download data from link below and unzip `train.csv` and `test.csv`\n",
    "\n",
    "Link to data: https://www.kaggle.com/shivamb/a-very-comprehensive-tutorial-nn-cnn/data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### MNIST dataset\n",
    "MNIST dataset is handwritten digits that is commonly used for training various image processing systems.\n",
    "  > Each image is 28*28.\n",
    "\n",
    "![mnist](https://upload.wikimedia.org/wikipedia/commons/2/27/MnistExamples.png)\n",
    "Source: wikipedia\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Preparation\n",
    "\n",
    "Load both train and test dataset.\n",
    "\n",
    "We are training a `binary classification`. For example, a model that can detect digits of `0` and `1`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# read train dataset\n",
    "train = pd.read_csv('./data/train.csv')\n",
    "\n",
    "# read test dataset, test data does not have lables\n",
    "test = pd.read_csv('./data/test.csv')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Get familiar with data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(42000, 785)\n",
      "Index(['label', 'pixel0', 'pixel1', 'pixel2', 'pixel3', 'pixel4', 'pixel5',\n",
      "       'pixel6', 'pixel7', 'pixel8',\n",
      "       ...\n",
      "       'pixel774', 'pixel775', 'pixel776', 'pixel777', 'pixel778', 'pixel779',\n",
      "       'pixel780', 'pixel781', 'pixel782', 'pixel783'],\n",
      "      dtype='object', length=785)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>label</th>\n",
       "      <th>pixel0</th>\n",
       "      <th>pixel1</th>\n",
       "      <th>pixel2</th>\n",
       "      <th>pixel3</th>\n",
       "      <th>pixel4</th>\n",
       "      <th>pixel5</th>\n",
       "      <th>pixel6</th>\n",
       "      <th>pixel7</th>\n",
       "      <th>pixel8</th>\n",
       "      <th>...</th>\n",
       "      <th>pixel774</th>\n",
       "      <th>pixel775</th>\n",
       "      <th>pixel776</th>\n",
       "      <th>pixel777</th>\n",
       "      <th>pixel778</th>\n",
       "      <th>pixel779</th>\n",
       "      <th>pixel780</th>\n",
       "      <th>pixel781</th>\n",
       "      <th>pixel782</th>\n",
       "      <th>pixel783</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 785 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   label  pixel0  pixel1  pixel2  pixel3  pixel4  pixel5  pixel6  pixel7  \\\n",
       "0      1       0       0       0       0       0       0       0       0   \n",
       "1      0       0       0       0       0       0       0       0       0   \n",
       "2      1       0       0       0       0       0       0       0       0   \n",
       "3      4       0       0       0       0       0       0       0       0   \n",
       "4      0       0       0       0       0       0       0       0       0   \n",
       "\n",
       "   pixel8  ...  pixel774  pixel775  pixel776  pixel777  pixel778  pixel779  \\\n",
       "0       0  ...         0         0         0         0         0         0   \n",
       "1       0  ...         0         0         0         0         0         0   \n",
       "2       0  ...         0         0         0         0         0         0   \n",
       "3       0  ...         0         0         0         0         0         0   \n",
       "4       0  ...         0         0         0         0         0         0   \n",
       "\n",
       "   pixel780  pixel781  pixel782  pixel783  \n",
       "0         0         0         0         0  \n",
       "1         0         0         0         0  \n",
       "2         0         0         0         0  \n",
       "3         0         0         0         0  \n",
       "4         0         0         0         0  \n",
       "\n",
       "[5 rows x 785 columns]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(train.shape)\n",
    "print(train.columns)\n",
    "train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# first shuffle train data\n",
    "train = train.sample(frac=1)\n",
    "\n",
    "# take 10% of train for validation\n",
    "\n",
    "# get number of datapoints\n",
    "num_datapoints = train.shape[0]\n",
    "\n",
    "# get 90% of total count\n",
    "num_train = int(num_datapoints*0.9)\n",
    "\n",
    "# get 10% of train for validation\n",
    "validation = train[num_train:]\n",
    "\n",
    "# get 90% for train\n",
    "train = train[:num_train]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get datapoint with only label 0 and 1\n",
    "X = train[train['label'].isin([0, 1])]\n",
    "\n",
    "# Get only label 0 and 1\n",
    "Y = train[train['label'].isin([0, 1])]['label']\n",
    "\n",
    "# Remove label from X.\n",
    "X = X.drop(['label'], axis = 1)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Activation Function\n",
    "\n",
    "We use sigmoid activation function as its output values are between 0 and 1 and it is good for binary classification."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![Sigmoid](https://upload.wikimedia.org/wikipedia/commons/thumb/8/88/Logistic-curve.svg/640px-Logistic-curve.svg.png \"Sigmoid\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![Sigmoid_Formula](https://wikimedia.org/api/rest_v1/media/math/render/svg/f6f69aad495c133ff951475da3d2ac0de3a0f571 \"Sigmoid\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sigmoid(z):\n",
    "    '''\n",
    "    Sigmoid activation function\n",
    "    '''\n",
    "    \n",
    "    sigmoid = 1.0/(1 + np.exp(-z))\n",
    "\n",
    "    return sigmoid\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Define Network Parameters\n",
    "\n",
    "Neural Network parameters are weights and bias. In this example we have one hidden layer.\n",
    "\n",
    "First we initialze them with zero values. \n",
    "\n",
    "The first layer only contains inputs so there are no weights and bias. (there is no W0 and b0)\n",
    "\n",
    "But the hidden layer and the output layer have a weight and bias term. (W1, b1 and W2, b2)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def define_network_parameters(num_x, num_y, nodes_hidden):\n",
    "    '''\n",
    "    Defining all network parameters\n",
    "    '''\n",
    "    \n",
    "    # Weight and bias for one hidden layer\n",
    "    # random initialization\n",
    "    W1 = np.random.randn(nodes_hidden, num_x) * 0.01\n",
    "    # zero initialization\n",
    "    b1 = np.zeros((nodes_hidden, 1))\n",
    "    \n",
    "    # Weight and bias for one output layer\n",
    "    # random initialization\n",
    "    W2 = np.random.randn(num_y, nodes_hidden) * 0.01\n",
    "    # zero initialization \n",
    "    b2 = np.zeros((num_y, 1))\n",
    "    \n",
    "    return {\"W1\": W1, \"b1\": b1, \"W2\": W2, \"b2\": b2}\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Note:\n",
    "\n",
    "#### `np.random.randn()` vs `np.random.rand()`\n",
    "\n",
    "`np.random.randn():` generates samples from the normal distribution\n",
    "\n",
    "`np.random.rand():` generates samples from uniform distribution\n",
    "\n",
    "https://stackoverflow.com/questions/47240308/differences-between-numpy-random-rand-vs-numpy-random-randn-in-python"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Network Forward Propagation\n",
    "\n",
    "The hidden layer and output layer will compute the activations using sigmoid activation function and will pass it in the forward direction. While computing this activation, the input is multiplied with weight and added with bias before passing it to the function.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def forward_propagation(X, params):\n",
    "    '''\n",
    "    Network forward propagation function.\n",
    "    '''\n",
    "    \n",
    "    # Hidden layer\n",
    "    Z1 = np.dot(params[\"W1\"], X) + params[\"b1\"]\n",
    "    Active1 = sigmoid(Z1)\n",
    "    \n",
    "    # Output layer\n",
    "    Z2 = np.dot(params[\"W2\"], Active1) + params[\"b2\"]\n",
    "    Active2 = sigmoid(Z2)\n",
    "    \n",
    "    return {\"Z1\": Z1, \"Active1\": Active1, \"Z2\": Z2, \"Active2\": Active2}\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Compute Network Error\n",
    "\n",
    "To be able to compute the cost one approach is to compute the absolute error (Prediction - Actual). But a better approach is the Log-Loss function which is defined as:\n",
    "\n",
    "More info:\n",
    "https://towardsdatascience.com/intuition-behind-log-loss-score-4e0c9979680a"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![logloss](https://miro.medium.com/max/1408/1*oS810EpSFnFilg9GGe2y2Q.png \"logloss\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__Loss__ function measures the error in the final layer.\n",
    "\n",
    "__Cost__ function measures the total error of the network."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def network_error(Predicted, Actual):\n",
    "    '''\n",
    "    Function to calculate network error\n",
    "    '''\n",
    "    \n",
    "    logLoss = np.multiply(np.log(Predicted), Actual) + np.multiply(np.log(1-Predicted), 1-Actual)\n",
    "    cost = -np.sum(logLoss) / Actual.shape[1]\n",
    "    \n",
    "    return np.squeeze(cost) # remove axes of length one\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Network Backward Propagation\n",
    "In backward propagation function, the error is passed backward to previous layers and the derivatives of weights and bias are computed.\n",
    "\n",
    "Because it is backward propagation then we start with output layer and then move back to hidden layer.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def backward_propagation(params, activations, X, Y):\n",
    "    '''\n",
    "    Network back propagation function.\n",
    "    '''\n",
    "    \n",
    "    m = X.shape[1]\n",
    "    \n",
    "    # Output layer\n",
    "    dZ2 = activations['Active2'] - Y # compute the error derivative \n",
    "    dW2 = np.dot(dZ2, activations['Active1'].T) / m # compute the weight derivative \n",
    "    db2 = np.sum(dZ2, axis=1, keepdims=True)/m # compute the bias derivative\n",
    "    \n",
    "    # Hidden layer\n",
    "    dZ1 = np.dot(params['W2'].T, dZ2)*(1-np.power(activations['Active1'], 2))\n",
    "    dW1 = np.dot(dZ1, X.T)/m\n",
    "    db1 = np.sum(dZ1, axis=1, keepdims=True)/m\n",
    "    \n",
    "    return {\"dW1\": dW1, \"db1\": db1, \"dW2\": dW2, \"db2\": db2}\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Update Network Parameters\n",
    "\n",
    "Given the derivatives of both weight and bias we update them for both hidden and output layer.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def update_parameters(params, derivatives, alpha=1.2):\n",
    "    '''\n",
    "    Function to update network parameters using derivatives\n",
    "    '''\n",
    "    \n",
    "    params['W1'] = params['W1'] - alpha * derivatives['dW1']\n",
    "    params['b1'] = params['b1'] - alpha * derivatives['db1']\n",
    "    params['W2'] = params['W2'] - alpha * derivatives['dW2']\n",
    "    params['b2'] = params['b2'] - alpha * derivatives['db2']\n",
    "    \n",
    "    return params\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train the Model\n",
    "\n",
    "Create a function which compiles all the key functions and creates a neural network model.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def nerual_network(X, Y, nodes_hidden, num_iterations):\n",
    "    '''\n",
    "    Main neural network function\n",
    "    '''\n",
    "\n",
    "    # X shape is  (784, 7968) \n",
    "    # Y shape is (1, 7968)\n",
    "    \n",
    "    num_x = X.shape[0] #784\n",
    "    num_y = Y.shape[0] #1\n",
    "    \n",
    "    params = define_network_parameters(num_x, num_y, nodes_hidden)\n",
    "    \n",
    "    errors = []\n",
    "\n",
    "    for i in range(0, num_iterations):\n",
    "        results = forward_propagation(X, params)\n",
    "        # last layer is Active2. Compare it with Y which is true label.\n",
    "        error = network_error(results['Active2'], Y)\n",
    "        derivatives = backward_propagation(params, results, X, Y)\n",
    "        params = update_parameters(params, derivatives)\n",
    "\n",
    "        errors.append(error)\n",
    "    \n",
    "    # plot the error\n",
    "    plt.plot(np.array(errors))\n",
    "    plt.title(\"Error\")\n",
    "\n",
    "    return params\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Library/Frameworks/Python.framework/Versions/3.7/lib/python3.7/site-packages/ipykernel_launcher.py:6: RuntimeWarning: overflow encountered in exp\n",
      "  \n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# prepare data to train model\n",
    "x = X.T.values\n",
    "y = Y.values.reshape(1, Y.size) # array([1, 0, 1, ..., 0, 0, 0]) to array([[1, 0, 1, ..., 0, 0, 0]])\n",
    "                                # Y.shape: (7894,)   -   y.shape: (1, 7894)\n",
    "\n",
    "# set number of nodes in our 1 hidden layer\n",
    "nodes_hidden = 10\n",
    "# set number of iterations to run the model\n",
    "num_iterations = 100\n",
    "\n",
    "# train the neural network\n",
    "model = nerual_network(x, y, nodes_hidden, num_iterations)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict(X, parameters):\n",
    "    '''\n",
    "    Function to predict digit from image\n",
    "    '''\n",
    "    results = forward_propagation(X, parameters)\n",
    "    predictions = np.around(results['Active2'])\n",
    "    return predictions\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Accuracy: 98%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Library/Frameworks/Python.framework/Versions/3.7/lib/python3.7/site-packages/ipykernel_launcher.py:6: RuntimeWarning: overflow encountered in exp\n",
      "  \n"
     ]
    }
   ],
   "source": [
    "predictions = predict(x, model)\n",
    "print ('Train Accuracy: %d' % float((np.dot(y, predictions.T) + np.dot(1-y, 1-predictions.T))/float(y.size)*100) + '%')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation Accuracy: 97%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Library/Frameworks/Python.framework/Versions/3.7/lib/python3.7/site-packages/ipykernel_launcher.py:10: FutureWarning: Method .as_matrix will be removed in a future version. Use .values instead.\n",
      "  # Remove the CWD from sys.path while we load stuff.\n",
      "/Library/Frameworks/Python.framework/Versions/3.7/lib/python3.7/site-packages/ipykernel_launcher.py:6: RuntimeWarning: overflow encountered in exp\n",
      "  \n"
     ]
    }
   ],
   "source": [
    "# Get datapoint with only label 0 and 1\n",
    "X_validation = validation[validation['label'].isin([0, 1])]\n",
    "\n",
    "# Get only label 0 and 1\n",
    "Y_validation = validation[validation['label'].isin([0, 1])]['label']\n",
    "\n",
    "# Remove label from X.\n",
    "X_validation = X_validation.drop(['label'], axis = 1)\n",
    "\n",
    "x_validation = X_validation.T.as_matrix()\n",
    "y_validation = Y_validation.values.reshape(1, Y_validation.size)\n",
    "\n",
    "predictions_validation = predict(x_validation, model)\n",
    "print ('Validation Accuracy: %d' % float((np.dot(y_validation, predictions_validation.T) + np.dot(1-y_validation, 1-predictions_validation.T))/float(y_validation.size)*100) + '%')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Source: https://www.kaggle.com/shivamb/a-very-comprehensive-tutorial-nn-cnn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.0b2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
